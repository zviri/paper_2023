{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "germ_output_path = \"\"\n",
    "node_label_mapping_path = \"\"\n",
    "nodes_path = \"\"\n",
    "edges_path = \"\" \n",
    "debtors_path = \"\"\n",
    "insolvency_data_path = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import os\n",
    "import sys\n",
    "import textwrap\n",
    "\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from sklearn.cluster import SpectralClustering\n",
    "from math import ceil\n",
    "from numpy import trapz\n",
    "from scipy import stats\n",
    "from tqdm import tqdm\n",
    "from IPython.display import display\n",
    "\n",
    "sns.set_palette(\"bright\")\n",
    "os.chdir(os.environ[\"EXPERIMENTS_HOMEDIR\"])\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "region_names = [\n",
    "    'Jihomoravský kraj', 'Jihočeský kraj', 'Karlovarský kraj',\n",
    "    'Kraj Vysočina', 'Královéhradecký kraj', 'Liberecký kraj',\n",
    "    'Moravskoslezský kraj', 'Olomoucký kraj', 'Pardubický kraj',\n",
    "    'Plzeňský kraj', 'Praha', 'Středočeský kraj', 'Zlínský kraj',\n",
    "    'Ústecký kraj'\n",
    "]\n",
    "\n",
    "population_per_region = {\n",
    "    'Jihomoravský kraj': 1184568, \n",
    "    'Jihočeský kraj': 637047, \n",
    "    'Karlovarský kraj': 283210,\n",
    "    'Kraj Vysočina': 504025, \n",
    "    'Královéhradecký kraj': 542583, \n",
    "    'Liberecký kraj': 437570,\n",
    "    'Moravskoslezský kraj': 1177989, \n",
    "    'Olomoucký kraj': 622930, \n",
    "    'Pardubický kraj': 514518,\n",
    "    'Plzeňský kraj': 578707, \n",
    "    'Praha': 1275406, \n",
    "    'Středočeský kraj': 1386824, \n",
    "    'Zlínský kraj': 572432,\n",
    "    'Ústecký kraj': 798898 \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_label_2_name = dict(\n",
    "    pd.read_csv(node_label_mapping_path)[[\"label\", \"idx\"]].values\n",
    ")\n",
    "node_label_2_name = {k: node_label_2_name[k].title().replace(\"_\", \" \") for k in node_label_2_name}\n",
    "for k, v in node_label_2_name.items():\n",
    "    if v == \"Debtor\":\n",
    "        node_label_2_name[k] = \"Other\"\n",
    "    if v == \"Nonbanking\":\n",
    "        node_label_2_name[k] = \"Lender\"\n",
    "    if v == \"Utilities\":\n",
    "        node_label_2_name[k] = \"Util.\"\n",
    "print(node_label_2_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _value_label_to_str(value_label):\n",
    "    return {\n",
    "        \"0\": \"0–11%\",\n",
    "        \"1\": \"11–31%\",\n",
    "        \"2\": \"31–52%\",\n",
    "        \"3\": \"52–79%\",\n",
    "        \"4\": \"79–100%\",\n",
    "    }[value_label]\n",
    "\n",
    "def render_graph(g, node_labels=None, edge_labels=None):\n",
    "    pos=nx.spring_layout(g, scale=0.7)\n",
    "    color_map=[sns.color_palette()[2]] + [sns.color_palette()[1]] * (len(list(g)) - 1)\n",
    "    nx.draw(g, pos, arrowsize=18,node_color=color_map, node_size=3500, edge_color=\"grey\", width=3)\n",
    "    if not edge_labels:\n",
    "        edge_labels=dict([((u,v),d[\"label\"] + \"Y\" + \"\\n\" + _value_label_to_str(d[\"value_label\"])) for u,v,d in g.edges(data=True)])\n",
    "    nx.draw_networkx_edge_labels(g,pos, edge_labels=edge_labels, font_size=15)\n",
    "    if node_labels:\n",
    "        nx.draw_networkx_labels(g, pos, labels=node_labels, font_size=16)\n",
    "    else:\n",
    "        nx.draw_networkx_labels(\n",
    "            g,\n",
    "            pos,\n",
    "            labels=dict([\n",
    "                (u, node_label_2_name[int(d[\"label\"])]) for u,d in g.nodes(data=True)\n",
    "            ]),\n",
    "            font_size=16\n",
    "        )\n",
    "    plt.show()\n",
    "    \n",
    "def calculate_confidence(graph, graphs):\n",
    "    edges = graph[\"graph\"].edges(data=True)\n",
    "    max_label = max(map(lambda e: int(e[2][\"label\"]), list(edges)))\n",
    "    selected_edges = [(ee[0], ee[1]) for ee in filter(lambda e: int(e[2][\"label\"]) < max_label, list(edges))]\n",
    "    body = graph[\"graph\"].edge_subgraph(selected_edges)\n",
    "    \n",
    "    for g in graphs:\n",
    "        if nx.is_isomorphic(\n",
    "            g[\"graph\"], \n",
    "            body, \n",
    "            edge_match=lambda e1, e2: e1[\"label\"] == e2[\"label\"] and e1[\"value_label\"] == e2[\"value_label\"], \n",
    "            node_match=lambda n1, n2: n1[\"label\"]==n2[\"label\"]\n",
    "        ):\n",
    "            return graph[\"support\"] / g[\"support\"]\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def load_projections(path, max_num_projections=sys.maxsize):\n",
    "    projections = defaultdict(list)\n",
    "    current_projection = None\n",
    "    graph_number = None\n",
    "    skip = False\n",
    "    for idx, line in enumerate(open(path)):\n",
    "        if not line.startswith(\"t\") and skip:\n",
    "            continue\n",
    "        if line.startswith(\"t\"):\n",
    "            skip = False\n",
    "            graph_number = int(line.split(\" \")[2])\n",
    "            continue\n",
    "        elif line.startswith(\"p\"):\n",
    "            if current_projection is not None:\n",
    "                projections[graph_number].append(current_projection)\n",
    "            if len(projections[graph_number]) >= max_num_projections:\n",
    "                skip = True\n",
    "                current_projection = None\n",
    "                continue\n",
    "            current_projection = nx.DiGraph()\n",
    "        elif line.startswith(\"e\"):\n",
    "            from_, to, label, value_label = line.split(\" \")[1:5]\n",
    "            current_projection.add_edge(int(from_), int(to), label=int(label), value_label=value_label)\n",
    "\n",
    "def _get_diff_months(end_date, min_date):\n",
    "    delta = relativedelta(end_date, min_date)\n",
    "    return delta.years * 12 + delta.months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_rule_2_debtors(debtors_path):\n",
    "    debtors_num_agg = []\n",
    "    graph_number = None\n",
    "    rule_2_debtors = {}\n",
    "    for line in open(debtors_path):\n",
    "        if line.startswith(\"t\"):\n",
    "            if debtors_num_agg:\n",
    "                rule_2_debtors[graph_number] = debtors_num_agg\n",
    "            debtors_num_agg = []\n",
    "            graph_number = int(line.split(\" \")[-1])\n",
    "            continue\n",
    "        else:\n",
    "            debtors_num_agg.append(int(line.strip()))\n",
    "    rule_2_debtors[graph_number] = debtors_num_agg\n",
    "    return rule_2_debtors\n",
    "\n",
    "def get_months_to_default(debtors):\n",
    "    debtors_df = pd.DataFrame(debtors, columns=[\"idx\"])\n",
    "    selected_nodes_df = nodes_df.merge(debtors_df, on=\"idx\")\n",
    "    selected_edges_df = edges_df.merge(selected_nodes_df[[\"idx\", \"id\", \"proposal_timestamp\"]], left_on=\"src_id\", right_on=\"id\")\n",
    "    selected_edges_df = selected_edges_df.sort_values(by=\"due_date\")\n",
    "    first_default_df = selected_edges_df.loc[selected_edges_df.groupby('src_id').due_date.idxmin()]\n",
    "    first_default_df[\"months_to_default\"] = ((first_default_df.proposal_timestamp - first_default_df.due_date)/np.timedelta64(1, 'M')).astype(int)\n",
    "    return first_default_df[\"months_to_default\"]\n",
    "\n",
    "def plot_months_to_default(m2d, pretty):\n",
    "    ax = m2d.hist(\n",
    "        bins=20,\n",
    "        figsize=(8,3),\n",
    "        range=(0,250)\n",
    "    )    \n",
    "    if not pretty:\n",
    "        ax.set_title(f\"Time to bankruptcy (MTTB={round(m2d.median(),3)}) months\")\n",
    "    plt.axvline(x=m2d.median(), color=sns.color_palette()[3], linewidth=4, linestyle=\"--\")\n",
    "    \n",
    "    label_bottom, label_top = ax.get_yticks()[-3], ax.get_yticks()[-2]\n",
    "    plt.text(m2d.median() + 5, label_bottom + (label_top-label_bottom) / 4,f\"MTTB={int(m2d.median())}\",rotation=0, color=sns.color_palette()[3], fontsize=16)\n",
    "    plt.xticks(fontsize=22)\n",
    "    plt.yticks(fontsize=22)\n",
    "    plt.xlabel(\"Months\", fontsize=22, labelpad=6)\n",
    "    plt.ylabel(\"# of debtors\", fontsize=22, labelpad=5)\n",
    "    plt.show()\n",
    "    \n",
    "def get_debt_accumulation_series(debtors):\n",
    "    debtors_df = pd.DataFrame(debtors, columns=[\"idx\"])\n",
    "    selected_nodes_df = nodes_df.merge(debtors_df, on=\"idx\")\n",
    "    selected_edges_df = edges_df.merge(selected_nodes_df[[\"idx\", \"id\", \"proposal_timestamp\"]], left_on=\"src_id\", right_on=\"id\")\n",
    "    selected_edges_df = selected_edges_df.sort_values(by=\"due_date\")\n",
    "\n",
    "    min_quarter_df = selected_edges_df.groupby(\"src_id\").agg(min_quarter=(\"label_monthly\", min)).reset_index()\n",
    "    selected_edges_df = selected_edges_df.merge(min_quarter_df, on=\"src_id\")\n",
    "    selected_edges_df[\"quarter\"] = selected_edges_df[\"label_monthly\"] - selected_edges_df[\"min_quarter\"]\n",
    "\n",
    "    sums_df=selected_edges_df.groupby([\"src_id\", \"quarter\"])[[\"value_percentage\"]].sum()\n",
    "    cum_sums_df = sums_df.reset_index().pivot_table(values=\"value_percentage\", index=\"src_id\", columns=\"quarter\").cumsum(axis=1)\n",
    "    cum_sums_df = cum_sums_df.T.fillna(method=\"ffill\")\n",
    "\n",
    "    if cum_sums_df.shape[0] < 130:\n",
    "        cum_sums_df = cum_sums_df.reindex(range(130)).fillna(method=\"ffill\")\n",
    "    else:\n",
    "        cum_sums_df = cum_sums_df[:130]\n",
    "\n",
    "    assert cum_sums_df.shape[0] == 130\n",
    "    \n",
    "    return cum_sums_df\n",
    "\n",
    "def plot_debt_accumulation(stats_df, pretty, mttb):\n",
    "    chart_df = pd.DataFrame()    \n",
    "    chart_df[\"Mean\"] = stats_df.mean(axis=1)\n",
    "    chart_df[\"Median\"] = stats_df.median(axis=1)\n",
    "    chart_df[\"std\"] = stats_df.std(axis=1)\n",
    "    if pretty:\n",
    "        # ax = chart_df[[\"Mean\"]].plot(figsize=(8,3), linewidth=4)\n",
    "        ax = chart_df[[\"Median\"]].plot(figsize=(8,3), linewidth=4)\n",
    "        pass\n",
    "    else:\n",
    "        ax = chart_df[[\"Mean\", \"std\"]].plot(figsize=(8,3), yerr='std', capsize=3)\n",
    "        chart_df[[\"Median\"]].plot(ax=ax, linewidth=4)\n",
    "    if mttb:\n",
    "        plt.axvline(x=mttb, color=sns.color_palette()[3], linewidth=4, linestyle=\"--\")\n",
    "        if mttb > ax.get_xlim()[1] - 10:\n",
    "            label_x = mttb-33\n",
    "        else:\n",
    "            label_x = mttb + 3\n",
    "        plt.text(label_x, 66,f\"MTTB={int(mttb)}\",rotation=0, color=sns.color_palette()[3], fontsize=18)\n",
    "    plt.xticks(fontsize=22)\n",
    "    plt.yticks(fontsize=22)\n",
    "    if not pretty:\n",
    "        ax.set_title(\"Debt accumulation\")\n",
    "    ax.set_ylim(0, 105)\n",
    "    ax.set_xlabel(\"Months\",  fontsize=22, labelpad=6)\n",
    "    ax.set_ylabel(\"Accumulated debt (%)\",  fontsize=18, labelpad=5)\n",
    "    ax.get_legend().remove()\n",
    "    plt.show()\n",
    "    \n",
    "def get_total_debt(debtors):\n",
    "    debtors_df = pd.DataFrame(debtors, columns=[\"idx\"])\n",
    "    selected_nodes_df = nodes_df.merge(debtors_df, on=\"idx\")\n",
    "    selected_edges_df = edges_df.merge(selected_nodes_df[[\"idx\", \"id\", \"proposal_timestamp\"]], left_on=\"src_id\", right_on=\"id\")\n",
    "    return selected_edges_df.groupby(\"src_id\")[[\"value\"]].sum().reset_index()\n",
    "    \n",
    "def get_nodes_for_rule(gid):\n",
    "    debtors = rule_2_debtors[gid]\n",
    "    debtors_df = pd.DataFrame(debtors, columns=[\"idx\"])\n",
    "    return nodes_df.merge(debtors_df, on=\"idx\")\n",
    "\n",
    "def get_categories_for_rule(gid):\n",
    "    stats_df = edges_df.merge(\n",
    "        get_nodes_for_rule(gid)[[\"id\"]], left_on=\"src_id\", right_on=\"id\"\n",
    "    ).merge(\n",
    "        nodes_df, left_on=\"dst_id\", right_on=\"id\"\n",
    "    ).groupby(\"category\").count()[[\"src_id\"]]\n",
    "    stats_df[\"perc\"] = stats_df[\"src_id\"] / stats_df[\"src_id\"].sum() * 100\n",
    "    stats_df.rename(columns={\"src_id\": \"count\", \"perc\": \"percentage\"})\n",
    "    return stats_df.round(1)\n",
    "\n",
    "def get_regional_stats_for_rule(gid):\n",
    "    region_stats_df = get_nodes_for_rule(gid).merge(\n",
    "        edges_df, left_on=\"id\", right_on=\"src_id\").merge(insolvency_data_df, on=\"insolvency_id\").groupby(\"region\").agg(rule_count=(\"id\", \"count\")\n",
    "    )\n",
    "    region_stats_df[\"rule_percentage\"] = region_stats_df[\"rule_count\"] / region_stats_df[\"rule_count\"].sum() * 100\n",
    "    region_stats_df = region_stats_df.merge(region_num_ins_df, on=\"region\")\n",
    "    region_stats_df[\"rule_percentage_vs_exp_ratio\"] = region_stats_df[\"rule_percentage\"] / region_stats_df[\"region_perc_ins\"]\n",
    "    region_stats_df[\"rule_percentage_per_region_ins\"] = (region_stats_df[\"rule_count\"] / region_stats_df[\"region_num_ins\"]) * 100\n",
    "    region_stats_df = region_stats_df.merge(pd.DataFrame(population_per_region.items(), columns=[\"region\", \"population_size\"]), on=\"region\")\n",
    "    region_stats_df[\"population_percentage\"] = region_stats_df[\"population_size\"] / region_stats_df[\"population_size\"].sum() * 100\n",
    "    region_stats_df[\"rule_percentage_vs_pop_exp_ratio\"] = region_stats_df[\"rule_percentage\"] / region_stats_df[\"population_percentage\"]\n",
    "    return region_stats_df.round(3)\n",
    "\n",
    "def analyze_rule(gid, pretty=False):\n",
    "    g = graphs[gid]\n",
    "    print(\"Number: \" + str(g[\"number\"]))\n",
    "    print(\"Support: \" + str(g[\"support\"]))\n",
    "    print(\"Confidence: \" + str(round(g[\"confidence\"]*100, 2)) + \" %\")  \n",
    "    debtors = rule_2_debtors[g[\"number\"]]\n",
    "    months_to_default = get_months_to_default(debtors)    \n",
    "    accumulation_series_df = get_debt_accumulation_series(debtors)\n",
    "    \n",
    "    individual_aucs = pd.Series([trapz(row) for _, row in accumulation_series_df.T.iterrows()])\n",
    "    corr_df = pd.DataFrame(zip(months_to_default, individual_aucs), columns=[\"months_to_default\", \"auc\"])\n",
    "    corr = round(corr_df['months_to_default'].corr(corr_df['auc']), 5)\n",
    "    print(f\"Correlation: {corr}\")\n",
    "    \n",
    "    render_graph(g[\"graph\"])\n",
    "    plot_months_to_default(months_to_default, pretty)\n",
    "    plot_debt_accumulation(accumulation_series_df, pretty, months_to_default.median())   \n",
    "    regional_stats_df = get_regional_stats_for_rule(gid)    \n",
    "    print(\"Regional stats\")\n",
    "    _, p_value_ins, _, _ = stats.chi2_contingency(regional_stats_df[[\"rule_count\", \"region_num_ins\"]])\n",
    "    print(f\"Insolvency count dependence test: chi_square_indepdence={p_value_ins > 0.05}, p-value={p_value_ins}\")\n",
    "    _, p_value_pop, _, _ = stats.chi2_contingency(regional_stats_df[[\"rule_count\", \"population_size\"]])\n",
    "    print(f\"Population count dependence test: chi_square_indepdence={p_value_pop > 0.05}, p-value={p_value_pop}\")\n",
    "    display(regional_stats_df.transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_df = pd.read_csv(nodes_path)\n",
    "nodes_df.id = nodes_df.id.astype(str)\n",
    "nodes_df[\"proposal_timestamp\"] = pd.to_datetime(nodes_df[\"proposal_timestamp\"])\n",
    "edges_df = pd.read_csv(edges_path)\n",
    "edges_df[\"due_date\"] = pd.to_datetime(edges_df[\"due_date\"])\n",
    "edges_df.src_id = edges_df.src_id.astype(str)\n",
    "edges_df.dst_id = edges_df.dst_id.astype(str)\n",
    "insolvency_data_df = pd.read_csv(insolvency_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_num_ins_df = insolvency_data_df[\n",
    "    insolvency_data_df.insolvency_id.apply(lambda iid: 2020 <= int(iid[-4:]) <= 2022)\n",
    "].groupby(\"region\").agg(region_num_ins=(\"insolvency_id\", \"count\")).reset_index()\n",
    "region_num_ins_df[\"region_perc_ins\"] = region_num_ins_df[\"region_num_ins\"] / region_num_ins_df[\"region_num_ins\"].sum() * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading patterns\n",
    "tmp_g = None\n",
    "support = None\n",
    "graph_number = None\n",
    "graphs = []\n",
    "for line in open(germ_output_path):\n",
    "    if line.startswith(\"t\"):\n",
    "        if tmp_g:\n",
    "            graphs.append({\"graph\": tmp_g, \"support\": support, \"number\": graph_number})\n",
    "            pass\n",
    "        tmp_g = nx.DiGraph()\n",
    "        support = int(line.split(\" \")[-1])\n",
    "        graph_number = int(line.split(\" \")[-2])\n",
    "        continue\n",
    "    if line.startswith(\"v\"):\n",
    "        parsed = line.strip().split(\" \")\n",
    "        tmp_g.add_node(parsed[1], label=parsed[2])\n",
    "    if line.startswith(\"e\"):\n",
    "        parsed = line.strip().split(\" \")\n",
    "        tmp_g.add_edge(parsed[1], parsed[2], label=parsed[3], value_label=parsed[4])  \n",
    "\n",
    "for g in graphs:\n",
    "    g[\"confidence\"] = calculate_confidence(g, graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading debtors per rule\n",
    "rule_2_debtors = load_rule_2_debtors(debtors_path)\n",
    "\n",
    "all_debtors = set()\n",
    "for gid in rule_2_debtors:\n",
    "    all_debtors = all_debtors.union(rule_2_debtors[gid])\n",
    "print(f\"Pocet uzlov pokrytych aspon jednym pravidlom: {len(all_debtors)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rule analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rules = []\n",
    "for row in tqdm(graphs):\n",
    "    debtors = rule_2_debtors[row[\"number\"]]\n",
    "    months_to_default = get_months_to_default(debtors)    \n",
    "    accumulation_series_df = get_debt_accumulation_series(debtors)\n",
    "    total_debt_df = get_total_debt(debtors)\n",
    "    \n",
    "    sum_jaccard = 0\n",
    "    for row2 in graphs:\n",
    "        debtors2 = rule_2_debtors[row2[\"number\"]]\n",
    "        debtors_set = set(debtors)\n",
    "        debtors2_set = set(debtors2)\n",
    "        num_intersect = len(debtors_set.intersection(debtors2_set))\n",
    "        num_union = len(debtors_set.union(debtors2_set))\n",
    "        sum_jaccard += num_intersect / num_union\n",
    "        \n",
    "    max_rule_label = max(map(lambda e: int(e[2][\"label\"]), row[\"graph\"].edges(data=True)))\n",
    "            \n",
    "    \n",
    "    individual_aucs = pd.Series([trapz(row) for _, row in accumulation_series_df.T.iterrows()])\n",
    "    corr_df = pd.DataFrame(zip(months_to_default, individual_aucs), columns=[\"months_to_default\", \"auc\"])\n",
    "    corr = round(corr_df['months_to_default'].corr(corr_df['auc']), 5)\n",
    "    \n",
    "    regional_stats_df = get_regional_stats_for_rule(row[\"number\"])    \n",
    "    _, p_value_ins, _, _ = stats.chi2_contingency(regional_stats_df[[\"rule_count\", \"region_num_ins\"]])\n",
    "    _, p_value_pop, _, _ = stats.chi2_contingency(regional_stats_df[[\"rule_count\", \"population_size\"]])\n",
    "    \n",
    "    regional_stats = dict(regional_stats_df.set_index(\"region\").rule_percentage_vs_exp_ratio.items())\n",
    "    rules.append(dict(\n",
    "        [\n",
    "            (\"gid\", row['number']), \n",
    "            (\"support\", row[\"support\"]),\n",
    "            (\"confidence\", row[\"confidence\"]),\n",
    "            (\"months_to_default_mean\", months_to_default.mean()), \n",
    "            (\"months_to_default_median\", months_to_default.median()), \n",
    "            (\"aucs_mean\", individual_aucs.mean()), \n",
    "            (\"aucs_median\", individual_aucs.median()), \n",
    "            (\"months_to_default_and_auc_corr\", corr),\n",
    "            (\"total_debt_mean\", total_debt_df.value.mean()),\n",
    "            (\"total_debt_median\", total_debt_df.value.median()),\n",
    "            (\"avg_overlap_with_others\", sum_jaccard / len(graphs)),\n",
    "            (\"max_rule_label\", max_rule_label),\n",
    "            (\"p_value_ins_independence\", p_value_ins),\n",
    "            (\"p_value_pop_independence\", p_value_pop),\n",
    "        ] + [(r, regional_stats.get(r, 0)) for r in region_names]\n",
    "    ))\n",
    "\n",
    "\n",
    "rules_df = pd.DataFrame(\n",
    "    rules,\n",
    ")\n",
    "rules_df[\"aucs_median_normalized\"] =  rules_df[\"aucs_median\"] / rules_df[\"aucs_median\"].max()\n",
    "rules_df[\"aucs_mean_normalized\"] =  rules_df[\"aucs_mean\"] / rules_df[\"aucs_mean\"].max()\n",
    "\n",
    "rules_df = rules_df[[\n",
    "    'gid', 'support', 'confidence', 'months_to_default_mean',\n",
    "    'months_to_default_median', 'aucs_mean', 'aucs_median', \n",
    "    'aucs_median_normalized', 'aucs_mean_normalized',\n",
    "    'months_to_default_and_auc_corr', 'total_debt_mean',\n",
    "    'total_debt_median', 'avg_overlap_with_others', 'max_rule_label',\n",
    "    'p_value_ins_independence', 'p_value_pop_independence'    \n",
    "] + region_names]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rule histograms"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = (rules_df.support[rules_df.support < 1000]).hist(\n",
    "    bins=40,\n",
    "    figsize=(8,3),\n",
    ")    \n",
    "\n",
    "plt.xticks(fontsize=18)\n",
    "plt.yticks(fontsize=18)\n",
    "plt.xlabel(\"Support\", fontsize=18, labelpad=6)\n",
    "plt.ylabel(\"# rules\", fontsize=18, labelpad=5)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = (rules_df.confidence * 100).hist(\n",
    "    bins=40,\n",
    "    figsize=(8,3),\n",
    ")    \n",
    "plt.xticks(fontsize=18)\n",
    "plt.yticks(fontsize=18)\n",
    "plt.xlabel(\"Confidence (%)\", fontsize=18, labelpad=6)\n",
    "plt.ylabel(\"# rules\", fontsize=18, labelpad=5)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MTTB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = (rules_df.months_to_default_median).hist(\n",
    "    bins=40,\n",
    "    figsize=(8,3),\n",
    ")    \n",
    "plt.xticks(fontsize=18)\n",
    "plt.yticks(fontsize=18)\n",
    "plt.xlabel(\"Median time to bankruptcy (MTTB) in months\", fontsize=18, labelpad=6)\n",
    "plt.ylabel(\"# rules\", fontsize=18, labelpad=5)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MDEBT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = (rules_df.total_debt_median * 0.046 / 1e6).hist(\n",
    "    bins=40,\n",
    "    figsize=(8,3),\n",
    ")    \n",
    "ax.xaxis.set_major_formatter('{x:.2g}M')\n",
    "plt.xticks(fontsize=18)\n",
    "plt.yticks(fontsize=18)\n",
    "plt.xlabel(\"Median total debt (MDEBT) in USD\", fontsize=18, labelpad=6)\n",
    "plt.ylabel(\"# rules\", fontsize=18, labelpad=5)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rules sorted by different metrics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rules based \"months to default\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rules_view_df = rules_df[rules_df.max_rule_label > 0].sort_values(by=\"months_to_default_median\")\n",
    "rules_view_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top rules\n",
    "for gid in rules_view_df[:5].gid:\n",
    "    analyze_rule(gid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bottom rules\n",
    "for gid in rules_view_df[-5:].gid:\n",
    "    analyze_rule(gid)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rules based on Debt AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rules_view_df = rules_df[rules_df.max_rule_label > 0].sort_values(by=\"aucs_median_normalized\")\n",
    "rules_view_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top rules\n",
    "for gid in rules_view_df[:5].gid:\n",
    "    analyze_rule(gid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bottom rules\n",
    "for gid in rules_view_df[-5:].gid:\n",
    "    analyze_rule(gid)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rules based Debt AUC and months to default correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rules_view_df = rules_df[rules_df.max_rule_label > 0].sort_values(by=\"months_to_default_and_auc_corr\")\n",
    "rules_view_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top rules\n",
    "for gid in rules_view_df[:5].gid:\n",
    "    analyze_rule(gid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bottom rules\n",
    "for gid in rules_view_df[-5:].gid:\n",
    "    analyze_rule(gid)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rules based on MDEBT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rules_view_df = rules_df[rules_df.max_rule_label > 0].sort_values(by=\"total_debt_median\")\n",
    "rules_view_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top rules\n",
    "for gid in rules_view_df[:5].gid:\n",
    "    analyze_rule(gid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bottom rules\n",
    "for gid in rules_view_df[-5:].gid:\n",
    "    analyze_rule(gid)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rules based on uniqueness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rules_view_df = rules_df[rules_df.max_rule_label > 0].sort_values(by=\"avg_overlap_with_others\")\n",
    "rules_view_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top rules\n",
    "for gid in rules_view_df[:5].gid:\n",
    "    analyze_rule(gid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bottom rules\n",
    "for gid in rules_view_df[-5:].gid:\n",
    "    analyze_rule(gid)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Praha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rules_view_df = rules_df[rules_df.max_rule_label > 0].sort_values(by=\"Praha\", ascending=False)\n",
    "rules_view_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top rules\n",
    "for gid in rules_view_df[:5].gid:\n",
    "    analyze_rule(gid)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ustecky kraj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rules_view_df = rules_df[rules_df.max_rule_label > 0].sort_values(by=\"Ústecký kraj\", ascending=False)\n",
    "rules_view_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top rules\n",
    "for gid in rules_view_df[:5].gid:\n",
    "    analyze_rule(gid)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overlap analysis of positively and negatively correlated rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlap_matrix = []\n",
    "index = []\n",
    "columns = []\n",
    "for gid_1, _ in sorted(rules_df[[\"gid\", \"months_to_default_and_auc_corr\"]].values, key=lambda p: p[1])[:10]:\n",
    "    gid_1 = int(gid_1)\n",
    "    overlap_matrix.append([])\n",
    "    columns.append(gid_1)\n",
    "    for gid_2, _ in sorted(rules_df[[\"gid\", \"months_to_default_and_auc_corr\"]].values, key=lambda p: p[1])[-10:]:\n",
    "        gid_2 = int(gid_2)\n",
    "        jaccard_index = (\n",
    "            len(set(rule_2_debtors[gid_1]).intersection(rule_2_debtors[gid_2])) / len(set(rule_2_debtors[gid_1]).union(rule_2_debtors[gid_2]))\n",
    "        )\n",
    "        if gid_2 not in index:\n",
    "            index.append(gid_2)\n",
    "        overlap_matrix[-1].append(jaccard_index)\n",
    "overlap_matrix_df = pd.DataFrame(overlap_matrix, index=index, columns=columns)\n",
    "overlap_matrix_df.style.background_gradient(cmap='Blues', axis=None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rules based on confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_charted_graphs = 0\n",
    "for row in sorted(graphs, key=lambda d: d[\"confidence\"], reverse=True)[:5]:\n",
    "    # if not any(map(lambda v: v[\"label\"] == '', dict(row[\"graph\"].nodes(data=True)).values())):\n",
    "    #     continue\n",
    "    # if not any(map(lambda e: e[2][\"value_label\"] == '', list(row[\"graph\"].edges(data=True)))):\n",
    "    #     continue\n",
    "    num_charted_graphs += 1\n",
    "    print(\"******************************************************\")\n",
    "    analyze_rule(row['number'])\n",
    "    if num_charted_graphs > 10:\n",
    "        break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rule matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlap_matrix = []\n",
    "index = []\n",
    "columns = []\n",
    "for gid_1, _ in rules_df[[\"gid\", \"months_to_default_and_auc_corr\"]].values:\n",
    "    overlap_matrix.append([])\n",
    "    columns.append(gid_1)\n",
    "    for gid_2, _ in rules_df[[\"gid\", \"months_to_default_and_auc_corr\"]].values:\n",
    "        jaccard_index = (\n",
    "            len(set(rule_2_debtors[gid_1]).intersection(rule_2_debtors[gid_2])) / len(set(rule_2_debtors[gid_1]).union(rule_2_debtors[gid_2]))\n",
    "        )\n",
    "        if gid_2 not in index:\n",
    "            index.append(gid_2)\n",
    "        overlap_matrix[-1].append(jaccard_index)\n",
    "overlap_matrix_df = pd.DataFrame(overlap_matrix, index=index, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters = 5\n",
    "clustering = SpectralClustering(\n",
    "    n_clusters=n_clusters,\n",
    "    assign_labels='discretize',\n",
    "    random_state=0,\n",
    "    affinity=\"precomputed\"\n",
    ").fit(overlap_matrix_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rules_df[\"cluster\"] = clustering.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.precision\", 8)\n",
    "clustering_stats_df = rules_df.groupby(\"cluster\").median().merge(\n",
    "    rules_df.groupby(\"cluster\").count()[[\"gid\"]].rename(columns={\"gid\": \"cluster_size\"}), left_index=True, right_index=True\n",
    ")\n",
    "clustering_stats_df.style.background_gradient(cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_overlaps = []\n",
    "for cluster_1 in range(n_clusters):\n",
    "    mean_overlaps.append([])\n",
    "    for cluster_2 in range(n_clusters):\n",
    "        columns = list(rules_df[rules_df[\"cluster\"] == cluster_1].gid)\n",
    "        rows = list(rules_df[rules_df[\"cluster\"] == cluster_2].gid)\n",
    "        avg_overlap = overlap_matrix_df[columns].loc[rows].stack().mean()\n",
    "        mean_overlaps[-1].append(avg_overlap)\n",
    "mean_overlaps_df = pd.DataFrame(mean_overlaps)\n",
    "mean_overlaps_df.style.background_gradient(cmap='Blues', axis=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('experiments-lib-sSN4AHN6-py3.8')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "7e4062e2dd0c4cad42606d4962dbfa7c599d655964b0cb5eecd376ffd74b6397"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
